{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. http://aiden.nibali.org/blog/2017-01-18-mode-collapse-gans/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.intra_op_parallelism_threads = 44\n",
    "config.inter_op_parallelism_threads = 44\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "from keras import backend as K\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 64)        1664      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 64)          102464    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 3137      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 107,265\n",
      "Trainable params: 107,265\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Activation\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers.core import Reshape, Dense, Dropout, Flatten\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import Conv2D, UpSampling2D\n",
    "from keras.datasets import mnist\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "from keras import initializers\n",
    "\n",
    "# Discriminator\n",
    "D = Sequential()\n",
    "D.add(Conv2D(64, kernel_size=(5, 5), strides=(2, 2), input_shape=(28, 28, 1), padding='same', kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n",
    "D.add(LeakyReLU(0.2))\n",
    "D.add(Dropout(0.3))\n",
    "D.add(Conv2D(64, kernel_size=(5, 5), strides=(2, 2), input_shape=(28, 28, 1), padding='same'))\n",
    "D.add(LeakyReLU(0.2))\n",
    "D.add(Dropout(0.3))\n",
    "D.add(Flatten())\n",
    "D.add(Dense(1))\n",
    "D.add(Activation('sigmoid'))\n",
    "D.summary()\n",
    "\n",
    "# compile\n",
    "optimizer = Adam(lr=0.0002, beta_1=0.5)\n",
    "D.compile(\n",
    "    loss='binary_crossentropy', \n",
    "    optimizer=optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 64)        204864    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 28, 28, 1)         1601      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 839,937\n",
      "Trainable params: 839,937\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=6272, kernel_initializer=<keras.ini..., input_dim=100)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# Generator\n",
    "G = Sequential()\n",
    "G.add(Dense(input_dim=100, output_dim=128*7*7, kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n",
    "G.add(LeakyReLU(0.2))\n",
    "G.add(Reshape((7, 7, 128)))\n",
    "G.add(UpSampling2D(size=(2, 2)))\n",
    "G.add(Conv2D(64, kernel_size=(5, 5), padding='same'))\n",
    "G.add(LeakyReLU(0.2))\n",
    "G.add(UpSampling2D(size=(2, 2)))\n",
    "G.add(Conv2D(1, (5, 5), padding='same'))\n",
    "G.add(Activation('tanh'))\n",
    "G.summary()\n",
    "\n",
    "# compile\n",
    "G.compile(\n",
    "    loss='binary_crossentropy', \n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile GAN\n",
    "D.trainable = False\n",
    "GAN = Sequential()\n",
    "GAN.add(G)\n",
    "GAN.add(D)\n",
    "GAN.compile(\n",
    "    loss='binary_crossentropy', \n",
    "    optimizer=optimizer\n",
    ")\n",
    "D.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch is', 0)\n",
      "('Number of batches', 234)\n",
      "batch 0 g_loss : 0.691882, d_loss : 0.690273\n",
      "batch 50 g_loss : 0.754781, d_loss : 0.653503\n",
      "batch 100 g_loss : 0.857651, d_loss : 0.664915\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = (X_train.astype(np.float32) - 127.5)/127.5\n",
    "X_train = X_train[:, :, :, None]\n",
    "X_test = X_test[:, :, :, None]\n",
    "\n",
    "EPOCH = 50\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "for EPOCH in range(100):\n",
    "    print(\"Epoch is\", EPOCH)\n",
    "    print(\"Number of batches\", int(X_train.shape[0]/BATCH_SIZE))\n",
    "    for index in range(int(X_train.shape[0]/BATCH_SIZE)):\n",
    "        # Get a random set of input noise and images\n",
    "        noise = np.random.normal(0, 1, size=[BATCH_SIZE, 100])\n",
    "        imageBatch = X_train[np.random.randint(0, X_train.shape[0], size=BATCH_SIZE)]\n",
    "        # Generate fake MNIST images\n",
    "        generatedImages = G.predict(noise)\n",
    "        X = np.concatenate([imageBatch, generatedImages])\n",
    "        # Labels for generated and real data\n",
    "        yDis = np.zeros(2*BATCH_SIZE)\n",
    "        # One-sided label smoothing from improved WGAN\n",
    "        yDis[:BATCH_SIZE] = 0.9\n",
    "        # Train discriminator\n",
    "        D.trainable = True\n",
    "        d_loss = D.train_on_batch(X, yDis)\n",
    "        # Train generator\n",
    "        noise = np.random.normal(0, 1, size=[BATCH_SIZE, 100])\n",
    "        yGen = np.ones(BATCH_SIZE)\n",
    "        D.trainable = False\n",
    "        g_loss = GAN.train_on_batch(noise, yGen)   \n",
    "        if index % 50 == 0:\n",
    "            print(\"batch %d g_loss : %f, d_loss : %f\" % (index, g_loss, d_loss))\n",
    "        \n",
    "    try_input = np.random.normal(0, 1, size=[100, 100])\n",
    "    preds = G.predict(try_input)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for i in range(preds.shape[0]):\n",
    "        plt.subplot(10, 10, i+1)\n",
    "        plt.imshow(preds[i, :, :, 0], cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
